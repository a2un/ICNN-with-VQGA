[general]
crop_size = 299
log_step = 10
embed_size = 16
hidden_size = 16
num_layers = 1
num_epochs = 2
batch_size = 128
num_workers = 2
learning_rate = 0.0001

[vqa]
model_dir = models/vqa
vocab_path = data/vocab/vocab_vqa.pkl

[vqg]
model_dir = models/vqg
vocab_path = data/vocab/vocab_vqg.pkl

[train]
image_dir = data/train
data_file_path = data/data_files/train_data.txt

[val]
image_dir = data/val
data_file_path = data/data_files/val_data.txt

[test]
image_dir = data/test
data_file_path = data/data_files/test_data.txt